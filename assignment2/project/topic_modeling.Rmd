---
title: "R Notebook"
output: html_notebook
---

## adapted from TidyTextMining Ch 6


```{r}
#library(tidyverse)
library(tidytext)
library(lubridate)
library(dplyr)
library(stringr)
library(tidyr)
library(topicmodels)
#library(scales)
```

```{r}
SABCNews_tweets <- read.csv("data/SABCNews_tweets.csv")
DailyMav_tweets <- read.csv("data/DailyMav_tweets.csv")
CapeTalk_tweets <- read.csv("data/CapeTalk_tweets.csv")
EWN_tweets <- read.csv("data/EWN_tweets.csv")
News24_tweets <- read.csv("data/News24_tweets.csv")
```


```{r}
filter_relevant_tweets <- function(tweets) {
  relevant_tweets <- tweets[grepl("covid", tweets[["text"]]) | 
                  grepl("Covid", tweets[["text"]]) |
                  grepl("corona", tweets[["text"]]) |
                  grepl("Corona", tweets[["text"]]) |
                  grepl("Pandemic", tweets[["text"]]) |
                  grepl("pandemic", tweets[["text"]]), ]
relevant_tweets <- relevant_tweets %>%
  mutate(created_at = ymd_hms(created_at))
}
```
```{r}
relevant_SABC <- filter_relevant_tweets(SABCNews_tweets)
relevant_DM <- filter_relevant_tweets(DailyMav_tweets)
relevant_CapeTalk <- filter_relevant_tweets(CapeTalk_tweets)
relevant_EWN <- filter_relevant_tweets(EWN_tweets)
relevant_News24 <- filter_relevant_tweets(News24_tweets)
```

```{r}
# combine all tweets into one dataframe
tweets <- bind_rows(relevant_SABC %>% 
                      mutate(user = "SABC"),
                    relevant_DM %>% 
                      mutate(user = "DailyMaverick"),
                    relevant_CapeTalk %>%
                      mutate(user = "CapeTalk"),
                    relevant_EWN %>%
                      mutate(user = "EWN"),
                    relevant_News24 %>%
                      mutate(user = "News24"))
```

```{r}
remove_stopwords <- function(tweets_in) {
  # define custom stopwords
  my_stopwords <- c("covid", "covid19", "corona", "coronavirus")
  # remove stopwords
  tidy_tweets <- tweets_in %>% 
    unnest_tokens(word, text, token = "tweets") %>%
    filter(!word %in% stop_words$word,
           !word %in% my_stopwords,
           !word %in% str_remove_all(stop_words$word, "'"),
           str_detect(word, "[a-z]"))
  return(tidy_tweets)
}
```
```{r}
tidy_tweets <- remove_stopwords(tweets)
```


# Topic Modelling

```{r}
model_topics_overall <- function(tidy_tweets_in, nr_of_topics) {
  # word count by media organisation
  word_counts <- tidy_tweets_in %>%
    select(user, word, created_at) %>%
    count(user, word, sort = TRUE) %>%
    ungroup()
  
  # create document term matrix
  # (treating all tweets from one organisation as one document)
  orgs_dtm <- word_counts %>%
    cast_dtm(user, word, n)
  
  # define number of topics
  k_topics = nr_of_topics
  # apply topic modelling
  orgs_lda <- LDA(orgs_dtm, k = k_topics, control = list(seed = 1234))
  
  orgs_topics <- tidy(orgs_lda, matrix = "beta")
  
  # find top words per topic
  top_terms <- orgs_topics %>%
    group_by(topic) %>%
    slice_max(beta, n = 5) %>% 
    ungroup() %>%
    arrange(topic, -beta)
  
  # plot top terms per topic
  top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(beta, term, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    scale_y_reordered()
}
```

```{r}
model_topics_overall(tidy_tweets, 4)
```

# topic modelling over time

```{r}
# past_month being the full date of the first day of that month - eg "2021-06-01" for June
model_topics_of_month <- function(past_month, nr_topics) {
  # word count by media organisation for specified month
  word_counts <- tidy_tweets %>%
    # create time bins (monthly)
    mutate(time_floor = floor_date(created_at, unit = "month")) %>%
    select(user, word, time_floor) %>%
    # filter to specified month
    filter(time_floor == as.Date(past_month)) %>%
    count(user, word, sort = TRUE) %>%
    ungroup()
    
  # create document term matrix
  # (treating all tweets from one organisation as one document)
  orgs_dtm <- word_counts %>%
    cast_dtm(user, word, n)

  # apply topic modelling
  orgs_lda <- LDA(orgs_dtm, k = nr_topics, control = list(seed = 1234))

  orgs_topics <- tidy(orgs_lda, matrix = "beta")

  # find top words per topic
  top_terms <- orgs_topics %>%
    group_by(topic) %>%
    slice_max(beta, n = 5) %>% 
    ungroup() %>%
    arrange(topic, -beta)

  # plot top terms per topic
  top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(beta, term, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    labs(title = paste("Topics for month starting", past_month)) +
    facet_wrap(~ topic, scales = "free") +
    scale_y_reordered()
}
```

```{r}
model_topics_of_month("2021-06-01", 4)
```
```{r}
model_topics_of_month("2021-05-01", 2)
# note: previous months have fewer topics because SABC only has data for June, anything before is only Daily Maverick
```
```{r}
model_topics_of_month("2021-04-01", 2)
```

# topic modelling per organisation

```{r}
# org being the name of the media agency as found in the tidy_tweets dataframe
model_topics_of_org <- function(org, nr_topics) {
  # word count for specified media organisation
  word_counts <- tidy_tweets %>%
    select(user, word) %>%
    # filter to specified org
    filter(user == org) %>%
    count(user, word, sort = TRUE) %>%
    ungroup()
    
  # create document term matrix
  # (treating all tweets from one organisation as one document)
  orgs_dtm <- word_counts %>%
    cast_dtm(user, word, n)

  # apply topic modelling
  orgs_lda <- LDA(orgs_dtm, k = nr_topics, control = list(seed = 1234))

  orgs_topics <- tidy(orgs_lda, matrix = "beta")

  # find top words per topic
  top_terms <- orgs_topics %>%
    group_by(topic) %>%
    slice_max(beta, n = 5) %>% 
    ungroup() %>%
    arrange(topic, -beta)

  # plot top terms per topic
  top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(beta, term, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    labs(title = paste("Topics for ", org)) +
    facet_wrap(~ topic, scales = "free") +
    scale_y_reordered()
}
```
```{r}
model_topics_of_org("DailyMaverick", 3)
```
```{r}
model_topics_of_org("SABC", 2)
```

```{r}
model_topics_of_org("CapeTalk", 2)
```

```{r}
model_topics_of_org("EWN", 2)
```

```{r}
model_topics_of_org("News24", 2)
```


# topic modelling for organisation for specific month

```{r}
# org being the name of the media agency as found in the tidy_tweets dataframe
model_topics_of_org_for_month <- function(org, past_month, nr_topics) {
  # word count for specified media organisation
  word_counts <- tidy_tweets %>%
    mutate(time_floor = floor_date(created_at, unit = "month")) %>%
    select(user, word, time_floor) %>%
    # filter to specified org
    filter(user == org) %>%
    # filter to specified month
    filter(time_floor == as.Date(past_month)) %>%
    count(user, word, sort = TRUE) %>%
    ungroup()
    
  # create document term matrix
  # (treating all tweets from one organisation as one document)
  orgs_dtm <- word_counts %>%
    cast_dtm(user, word, n)

  # apply topic modelling
  orgs_lda <- LDA(orgs_dtm, k = nr_topics, control = list(seed = 1234))

  orgs_topics <- tidy(orgs_lda, matrix = "beta")

  # find top words per topic
  top_terms <- orgs_topics %>%
    group_by(topic) %>%
    slice_max(beta, n = 5) %>% 
    ungroup() %>%
    arrange(topic, -beta)

  # plot top terms per topic
  top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(beta, term, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    labs(title = paste("Topics for ", org, " for month starting ", past_month)) +
    facet_wrap(~ topic, scales = "free") +
    scale_y_reordered()
}
```
```{r}
model_topics_of_org_for_month("DailyMaverick", "2021-06-01", 3)
```
```{r}
model_topics_of_org_for_month("SABC", "2021-06-01", 3)

```


```{r}
model_topics_of_org_for_month("CapeTalk", "2021-06-01", 3)
model_topics_of_org_for_month("EWN", "2021-06-01", 3)
model_topics_of_org_for_month("News24", "2021-06-01", 3)

```

