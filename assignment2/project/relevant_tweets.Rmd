---
title: "R Notebook"
output: html_notebook
---

## adapted from TidyTextMining Ch 7


```{r}
library(tidyverse)
library(tidytext)
library(lubridate)
library(dplyr)
library(stringr)
library(scales)
library(gridExtra)
library(grid)
```

```{r}
SABCNews_tweets <- read.csv("data/SABCNews_tweets.csv")
DailyMav_tweets <- read.csv("data/DailyMav_tweets.csv")
CapeTalk_tweets <- read.csv("data/CapeTalk_tweets.csv")
EWN_tweets <- read.csv("data/EWN_tweets.csv")
News24_tweets <- read.csv("data/News24_tweets.csv")
```

```{r}
filter_relevant_tweets <- function(tweets) {
  relevant_tweets <- tweets[grepl("covid", tweets[["text"]]) | 
                  grepl("Covid", tweets[["text"]]) |
                  grepl("corona", tweets[["text"]]) |
                  grepl("Corona", tweets[["text"]]) |
                  grepl("Pandemic", tweets[["text"]]) |
                  grepl("pandemic", tweets[["text"]]), ]
relevant_tweets <- relevant_tweets %>%
  mutate(created_at = ymd_hms(created_at))
}
```
```{r}
relevant_SABC <- filter_relevant_tweets(SABCNews_tweets)
relevant_DM <- filter_relevant_tweets(DailyMav_tweets)
relevant_CapeTalk <- filter_relevant_tweets(CapeTalk_tweets)
relevant_EWN <- filter_relevant_tweets(EWN_tweets)
relevant_News24 <- filter_relevant_tweets(News24_tweets)
```

```{r}
# plot daily maverick tweet freq over time
ggplot(relevant_DM, aes(x = created_at)) +
  geom_histogram(position = "identity", bins = 30, show.legend = FALSE) +
  labs(title = "Daily Maverick Tweet Frequency over Time")
```
# Comparing Tweet Frequency over Time
```{r}
# combine all tweets into one dataframe
tweets <- bind_rows(relevant_SABC %>% 
                      mutate(user = "SABC"),
                    relevant_DM %>% 
                      mutate(user = "DailyMaverick"),
                    relevant_CapeTalk %>%
                      mutate(user = "CapeTalk"),
                    relevant_EWN %>%
                      mutate(user = "EWN"),
                    relevant_News24 %>%
                      mutate(user = "News24"))
```

```{r}
# plot tweet frequency over time by org
ggplot(tweets, aes(x = created_at, fill = user)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~user, ncol = 1)
```

# word frequencies

```{r}
# define custom stopwords
my_stopwords <- c("covid", "covid19", "corona", "coronavirus")
# remove stopwords
tidy_tweets <- tweets %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% my_stopwords,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"))
```
```{r}
# calculate frequency of words by organisation
frequency_wide <- tidy_tweets %>% 
  group_by(user) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% 
              group_by(user) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)
frequency_wide
```

```{r}
# frequency of words per organisation (tidier)
frequency <- frequency_wide %>% 
  select(user, word, freq) %>% 
  pivot_wider(names_from = user, values_from = freq)
frequency
```



```{r}
# comparing most frequent words of SABC and Daily Maverick
ggplot(frequency, aes(SABC, DailyMaverick)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format())
  # geom_abline(color = "red")
```


# Top words per organisation
```{r}
# top n words to consider
n_words <- 10
```

```{r}
# top words SABC
top_words_SABC <- frequency %>%
  select(word, SABC) %>%
  arrange(desc(SABC))
top_words_SABC
# top words Daily Maverick
top_words_DM <- frequency %>%
  select(word, DailyMaverick) %>%
  arrange(desc(DailyMaverick))
top_words_DM
# top words Cape Talk
top_words_CapeTalk <- frequency %>%
  select(word, CapeTalk) %>%
  arrange(desc(CapeTalk))
top_words_CapeTalk
# top words Daily Maverick
top_words_EWN <- frequency %>%
  select(word, EWN) %>%
  arrange(desc(EWN))
top_words_EWN
# top words Daily Maverick
top_words_News24 <- frequency %>%
  select(word, News24) %>%
  arrange(desc(News24))
top_words_News24
```
```{r}
# top n words per organisation
top_n <- frequency_wide %>%
  group_by(user) %>%
  slice_max(order_by = freq, n=n_words) %>%
  ungroup

users <- unique(top_n[c("user")])

# Finding maximum length
ln <- top_n %>%
  group_by(user) %>%
  count()
ln
max_ln <- max(ln$n)


top_n_per_org <- data.frame(top_n %>% filter(user == "SABC") %>% select(word)) %>%
  mutate(SABC = word) %>%
  select(SABC)
for (i in seq(nrow(users[1]))) {
  top_n_of_org <- top_n %>% filter(user == users$user[i]) %>% select(word)
  top_n_per_org[[users$user[i]]] = head(top_n_of_org, n_words)
}

top_n_per_org <- top_n_per_org %>% unnest() %>% head(n_words)
top_n_per_org
```

```{r}
# https://stackoverflow.com/questions/31796219/grid-table-and-tablegrob-in-gridextra-package
# https://cran.r-project.org/web/packages/gridExtra/vignettes/tableGrob.html#faster-tables-an-alternative-grid-function
grid.newpage()
grid.table(top_n_per_org)
```

# Top n words overall

```{r}
# frequency of words overall (not per org)
overall_frequency <- tidy_tweets %>%
  select(word) %>%
  count(word) %>%
  arrange(n) %>%
  mutate(total = sum(n))

overall_frequency$word <- factor(overall_frequency$word, levels = overall_frequency$word)
overall_frequency
```
```{r}
# plot most frequently used words
ggplot(tail(overall_frequency,20), aes(word, n)) +
  geom_col() +
  labs(title = "Top 20 words overall") +
  coord_flip()
```
# Top hashtags

```{r}
# calculate frequency of hashtags by organisation
frequency_wide_ht <- tidy_tweets %>% 
  filter(str_detect(word, "^#")) %>%
  group_by(user) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% 
              group_by(user) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)
frequency_wide_ht
```

```{r}
# frequency of hashtags per organisation (tidier)
frequency_ht <- frequency_wide_ht %>% 
  select(user, word, freq) %>% 
  pivot_wider(names_from = user, values_from = freq)
frequency_ht
```
```{r}
# top n hashtags to consider
n_hashtags <- 3
```

```{r}
# top n hashtags per organisation
top_n_ht <- frequency_wide_ht %>%
  group_by(user) %>%
  slice_max(order_by = freq, n=n_hashtags) %>%
  ungroup
top_n_ht

users <- unique(top_n_ht[c("user")])

# Finding maximum length
ln <- top_n_ht %>%
  group_by(user) %>%
  count()
ln
max_ln <- max(ln$n)

top_n_per_org_ht <- data.frame(top_n_ht %>% filter(user == "SABC") %>% select(word)) %>%
  mutate(SABC = word) %>%
  select(SABC)

for (i in seq(nrow(users[1]))) {
  top_n_of_org_ht <- top_n_ht %>% filter(user == users$user[i]) %>% select(word)
  top_n_per_org_ht[[users$user[i]]] = head(top_n_of_org_ht, n_words)
  
  #top_n_per_org_ht[[users$user[i]]] = (top_n_ht %>% filter(user == users$user[i]) %>% select(word))
}

top_n_per_org_ht <- top_n_per_org_ht %>% unnest() %>% head(n_hashtags)
top_n_per_org_ht
```

```{r}
grid.newpage()
grid.table(top_n_per_org_ht)
```


# Top n hashtags overall

```{r}
# frequency of hashtags overall (not per org)
overall_frequency_ht <- tidy_tweets %>%
  filter(str_detect(word, "^#")) %>%
  select(word) %>%
  count(word) %>%
  arrange(n) %>%
  mutate(total = sum(n))

overall_frequency_ht$word <- factor(overall_frequency_ht$word, levels = overall_frequency_ht$word)
overall_frequency_ht
```
```{r}
# plot most frequently used hashtags
ggplot(tail(overall_frequency_ht,20), aes(word, n)) +
  geom_col() +
  labs(title = "Top 20 hashtags overall") +
  coord_flip()
```

# hashtag usage over time

```{r}
ht_by_time <- tidy_tweets %>%
  # only consider hashtags
  filter(str_detect(word, "^#")) %>%
  # create time bins
  mutate(time_floor = floor_date(created_at, unit = "week")) %>%
  # count how often each org uses each hashtag in each bin
  count(time_floor, user, word) %>%
  # add column for the total number hashtags used by each org in each time bin
  group_by(user, time_floor) %>%
  mutate(time_total = sum(n)) %>%
  # add column for the total number of times each hashtag was used by each org
  group_by(user, word) %>%
  mutate(word_total = sum(n)) %>%
  ungroup() %>%
  rename(count = n) %>%
  # consider only top hashtags
   filter(word_total > 15)

#ht_by_time <- ht_by_time %>%
#  group_by(user) %>%
#  filter(!duplicated(word)) %>%
#  slice_max(order_by = word_total, n=5) %>%
#  ungroup

ht_by_time
```
```{r}
library(purrr)
library(broom)
# create a dataframe with one row for each user-word combination, remaining data as a tibble in the last column
nested_data <- ht_by_time %>%
  nest(-word, -user) 
nested_data

# model to determine the change in frequency over time as slopes
nested_models <- nested_data %>%
  mutate(models = map(data, ~ glm(cbind(count, time_total) ~ time_floor, ., 
                                  family = "binomial")))
nested_models

# extract slopes
slopes <- nested_models %>%
  mutate(models = map(models, tidy)) %>%
  unnest(cols = c(models)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))
slopes
```

```{r}
# plot change of hashtag usage over time for SABC
ht_by_time %>%
  inner_join(slopes, by = c("word", "user")) %>%
  filter(user == "SABC") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")
```

```{r}
# plot change of word usage over time for daily maverick
ht_by_time %>%
  inner_join(slopes, by = c("word", "user")) %>%
  filter(user == "DailyMaverick") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")

# NOTE: daily maverick has no frequent hashtags
```

```{r}
# plot comparison of word usage over time by orgs

ht_by_time_slopes <- ht_by_time %>%
  inner_join(slopes, by = c("word", "user"))


ggplot(ht_by_time_slopes, aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  facet_wrap(~user, ncol = 1) +
  labs(x = NULL, y = "Word frequency")
```

# word usage over time

```{r}
words_by_time <- tidy_tweets %>%
  #filter(!str_detect(word, "^@")) %>%
  # create time bins
  mutate(time_floor = floor_date(created_at, unit = "week")) %>%
  # count how often each org uses each word in each bin
  count(time_floor, user, word) %>%
  # add column for the total number words used by each org in each time bin
  group_by(user, time_floor) %>%
  mutate(time_total = sum(n)) %>%
  # add column for the total number of times each word was used by each org
  group_by(user, word) %>%
  mutate(word_total = sum(n)) %>%
  ungroup() %>%
  rename(count = n) %>%
  # consider only top words
  filter(word_total > 35)

words_by_time
```
```{r}
library(purrr)
library(broom)
# create a dataframe with one row for each user-word combination, remaining data as a tibble in the last column
nested_data <- words_by_time %>%
  nest(-word, -user) 
nested_data

# model to determine the change in frequency over time as slopes
nested_models <- nested_data %>%
  mutate(models = map(data, ~ glm(cbind(count, time_total) ~ time_floor, ., 
                                  family = "binomial")))
nested_models

# extract slopes
slopes <- nested_models %>%
  mutate(models = map(models, tidy)) %>%
  unnest(cols = c(models)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))
slopes
```

```{r}
# plot change of word usage over time for SABC
words_by_time %>%
  inner_join(slopes, by = c("word", "user")) %>%
  filter(user == "SABC") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")
```

```{r}
# plot change of word usage over time for daily maverick
words_by_time %>%
  inner_join(slopes, by = c("word", "user")) %>%
  filter(user == "DailyMaverick") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")
```

```{r}
# plot comparison of word usage over time by orgs

words_by_time_slopes <- words_by_time %>%
  inner_join(slopes, by = c("word", "user"))


ggplot(words_by_time_slopes, aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  facet_wrap(~user, ncol = 1) +
  labs(x = NULL, y = "Word frequency")
```




