---
title: "R Notebook"
output: html_notebook
---
```{r}
library(tidyverse)
library(tidytext)
library(lubridate)
library(dplyr)
library(stringr)
library(scales)
```

```{r}
SABCNews_tweets <- read.csv("data/SABCNews_tweets.csv")
DailyMav_tweets <- read.csv("data/DailyMav_tweets.csv")
```
```{r}
relevant_SABC <- SABCNews_tweets[grepl("covid", SABCNews_tweets[["text"]]) | 
                  grepl("Covid", SABCNews_tweets[["text"]]) |
                  grepl("corona", SABCNews_tweets[["text"]]) |
                  grepl("Corona", SABCNews_tweets[["text"]]) |
                  grepl("Pandemic", SABCNews_tweets[["text"]]) |
                  grepl("pandemic", SABCNews_tweets[["text"]]), ]
relevant_SABC <- relevant_SABC %>%
  mutate(created_at = ymd_hms(created_at))

tail(relevant_SABC)
```

```{r}
relevant_DM <- DailyMav_tweets[grepl("covid", DailyMav_tweets[["text"]]) | 
                  grepl("Covid", DailyMav_tweets[["text"]]) |
                  grepl("corona", DailyMav_tweets[["text"]]) |
                  grepl("Corona", DailyMav_tweets[["text"]]) |
                  grepl("Pandemic", DailyMav_tweets[["text"]]) |
                  grepl("pandemic", DailyMav_tweets[["text"]]), ]
relevant_DM <- relevant_DM %>%
  mutate(created_at = ymd_hms(created_at))

tail(relevant_DM)
```


```{r}
ggplot(relevant_DM, aes(x = created_at)) +
  geom_histogram(position = "identity", bins = 30, show.legend = FALSE)
```

```{r}
# adapted from TidyTextMining Ch 7
tweets <- bind_rows(relevant_SABC %>% 
                      mutate(user = "SABC"),
                    relevant_DM %>% 
                      mutate(user = "DailyMaverick"))

ggplot(tweets, aes(x = created_at, fill = user)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~user, ncol = 1)
```

# word frequencies

```{r}
my_stopwords <- c("covid", "covid19", "corona", "coronavirus")
tidy_tweets <- tweets %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% my_stopwords,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"))
```
```{r}
frequency <- tidy_tweets %>% 
  group_by(user) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% 
              group_by(user) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)
frequency
```

```{r}
frequency <- frequency %>% 
  select(user, word, freq) %>% 
  pivot_wider(names_from = user, values_from = freq)
frequency
```

```{r}
ggplot(frequency, aes(SABC, DailyMaverick)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format())
  # geom_abline(color = "red")
```

# word usage

```{r}

```




