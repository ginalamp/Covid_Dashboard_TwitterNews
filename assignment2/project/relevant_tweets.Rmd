---
title: "R Notebook"
output: html_notebook
---
```{r}
library(tidyverse)
library(tidytext)
library(lubridate)
library(dplyr)
library(stringr)
library(scales)
```

```{r}
SABCNews_tweets <- read.csv("data/SABCNews_tweets.csv")
DailyMav_tweets <- read.csv("data/DailyMav_tweets.csv")
```
```{r}
relevant_SABC <- SABCNews_tweets[grepl("covid", SABCNews_tweets[["text"]]) | 
                  grepl("Covid", SABCNews_tweets[["text"]]) |
                  grepl("corona", SABCNews_tweets[["text"]]) |
                  grepl("Corona", SABCNews_tweets[["text"]]) |
                  grepl("Pandemic", SABCNews_tweets[["text"]]) |
                  grepl("pandemic", SABCNews_tweets[["text"]]), ]
relevant_SABC <- relevant_SABC %>%
  mutate(created_at = ymd_hms(created_at))

tail(relevant_SABC)
```

```{r}
relevant_DM <- DailyMav_tweets[grepl("covid", DailyMav_tweets[["text"]]) | 
                  grepl("Covid", DailyMav_tweets[["text"]]) |
                  grepl("corona", DailyMav_tweets[["text"]]) |
                  grepl("Corona", DailyMav_tweets[["text"]]) |
                  grepl("Pandemic", DailyMav_tweets[["text"]]) |
                  grepl("pandemic", DailyMav_tweets[["text"]]), ]
relevant_DM <- relevant_DM %>%
  mutate(created_at = ymd_hms(created_at))

tail(relevant_DM)
```


```{r}
ggplot(relevant_DM, aes(x = created_at)) +
  geom_histogram(position = "identity", bins = 30, show.legend = FALSE)
```

```{r}
# adapted from TidyTextMining Ch 7
tweets <- bind_rows(relevant_SABC %>% 
                      mutate(user = "SABC"),
                    relevant_DM %>% 
                      mutate(user = "DailyMaverick"))

ggplot(tweets, aes(x = created_at, fill = user)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~user, ncol = 1)
```

# word frequencies

```{r}
my_stopwords <- c("covid", "covid19", "corona", "coronavirus")
tidy_tweets <- tweets %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% my_stopwords,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"))
```
```{r}
frequency_wide <- tidy_tweets %>% 
  group_by(user) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% 
              group_by(user) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)
frequency_wide
```

```{r}
frequency <- frequency_wide %>% 
  select(user, word, freq) %>% 
  pivot_wider(names_from = user, values_from = freq)
frequency
```



```{r}
ggplot(frequency, aes(SABC, DailyMaverick)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format())
  # geom_abline(color = "red")
```


# Top words per organisation
```{r}
n_words <- 10
```

```{r}
# top words SABC
top_words_SABC <- frequency %>%
  select(word, SABC) %>%
  arrange(desc(SABC))
top_words_SABC
# top words Daily Maverick
top_words_DM <- frequency %>%
  select(word, DailyMaverick) %>%
  arrange(desc(DailyMaverick))
top_words_DM
```
```{r}
# top n words per organisation
top_n <- frequency_wide %>%
  group_by(user) %>%
  slice_max(order_by = freq, n=n_words) %>%
  ungroup

users <- unique(top_n[c("user")])

top_n_per_org <- data.frame(top_n %>% filter(user == "SABC") %>% select(word)) %>%
  mutate(SABC = word) %>%
  select(SABC)
for (i in seq(nrow(users[1]))) {
  top_n_per_org[[users$user[i]]] = (top_n %>% filter(user == users$user[i]) %>% select(word))
}

top_n_per_org
# the output here is weird, but click on top_n_per_org in the global environment -> open in tab with correct values
```


# word usage

```{r}

```




